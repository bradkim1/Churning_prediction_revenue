{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bfd2f2d-2fc3-40a2-aecf-60d133c836f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/studio-lab-user/.config/sagemaker/config.yaml\n",
      "Training Accuracy: 1.00\n",
      "Model saved to /home/studio-lab-user/model_output/model.joblib\n"
     ]
    }
   ],
   "source": [
    "#churning prdiction revenue\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialization function for SageMaker.\n",
    "    Loads model artifacts from disk and returns a model object for inference.\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(model_dir, \"model.joblib\")\n",
    "    model = joblib.load(model_path)\n",
    "    return model\n",
    "\n",
    "def run_training(train_dir, model_dir):\n",
    "    \"\"\"\n",
    "    Reads 'train.csv' from train_dir, trains a RandomForest model,\n",
    "    then saves 'model.joblib' to model_dir.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    # Load training data\n",
    "    train_path = os.path.join(train_dir, \"train.csv\")\n",
    "    data = pd.read_csv(train_path)\n",
    "\n",
    "    # Extract features and target\n",
    "    X = data[['monthly_charges', 'tenure_months', 'support_tickets']]\n",
    "    y = data['is_churn']\n",
    "\n",
    "    # Train Random Forest\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Evaluate (on training data for demonstration)\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(f\"Training Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_path = os.path.join(model_dir, \"model.joblib\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def run_local_orchestration():\n",
    "    \"\"\"\n",
    "    Generates synthetic data, uploads to S3, starts a SageMaker training job,\n",
    "    deploys the model, and runs a test inference. Used when running locally.\n",
    "    \"\"\"\n",
    "    session = sagemaker.Session()\n",
    "    role = get_execution_role()\n",
    "    region = session.boto_region_name\n",
    "    bucket = session.default_bucket()\n",
    "    prefix = \"churn-filter-args-example\"\n",
    "\n",
    "    # 1. Generate synthetic data\n",
    "    np.random.seed(42)\n",
    "    num_customers = 1000\n",
    "    monthly_charges = np.random.randint(20, 150, num_customers)\n",
    "    tenure_months = np.random.randint(1, 36, num_customers)\n",
    "    support_tickets = np.random.randint(0, 5, num_customers)\n",
    "\n",
    "    churn_probability = (\n",
    "        0.001 * monthly_charges\n",
    "        + 0.03 * support_tickets\n",
    "        + 0.0005 * (36 - tenure_months)\n",
    "    )\n",
    "    is_churn = (np.random.rand(num_customers) < churn_probability).astype(int)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'monthly_charges': monthly_charges,\n",
    "        'tenure_months': tenure_months,\n",
    "        'support_tickets': support_tickets,\n",
    "        'is_churn': is_churn\n",
    "    })\n",
    "\n",
    "    # Save locally\n",
    "    os.makedirs(\"project_data\", exist_ok=True)\n",
    "    train_file_path = os.path.join(\"project_data\", \"train.csv\")\n",
    "    data.to_csv(train_file_path, index=False)\n",
    "    print(f\"Local CSV saved at: {train_file_path}\")\n",
    "\n",
    "    # 2. Upload data to S3\n",
    "    train_s3_path = session.upload_data(\n",
    "        path=train_file_path,\n",
    "        bucket=bucket,\n",
    "        key_prefix=prefix\n",
    "    )\n",
    "    print(f\"Training data uploaded to: {train_s3_path}\")\n",
    "\n",
    "    # 3. Create scikit-learn Estimator\n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point=__file__,  # Use this same script as our \"entry point\"\n",
    "        role=role,\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        framework_version=\"1.2-1\",\n",
    "        py_version=\"py3\",\n",
    "        sagemaker_session=session\n",
    "    )\n",
    "\n",
    "    # 4. Fit (train) the model\n",
    "    sklearn_estimator.fit({\"train\": TrainingInput(train_s3_path, content_type=\"text/csv\")})\n",
    "\n",
    "    # 5. Deploy the model to an endpoint\n",
    "    endpoint_name = \"churn-filter-args-endpoint\"\n",
    "    predictor = sklearn_estimator.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "\n",
    "    # 6. Test the endpoint\n",
    "    sample_data = data.sample(5)\n",
    "    input_for_inference = sample_data[['monthly_charges','tenure_months','support_tickets']].values.tolist()\n",
    "    prediction = predictor.predict(input_for_inference)\n",
    "    print(\"Sample input:\\n\", sample_data)\n",
    "    print(\"Predicted churn labels (0=no churn, 1=churn):\", prediction)\n",
    "\n",
    "    # Uncomment below to delete the endpoint when finished\n",
    "    # predictor.delete_endpoint()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    When run with 'python sagemaker_churn_pipeline.py run-local', \n",
    "    it executes run_local_orchestration().\n",
    "    \n",
    "    Otherwise, it expects to receive arguments consistent with SageMaker \n",
    "    (e.g., --train /opt/ml/input/data/train --model-dir /opt/ml/model),\n",
    "    or uses default project directories if no arguments are provided.\n",
    "    \n",
    "    Any extraneous Jupyter arguments (-f /path/to/kernel.json) are filtered out.\n",
    "    \"\"\"\n",
    "    if len(sys.argv) > 1 and sys.argv[1] == \"run-local\":\n",
    "        # Local run: orchestrate data generation, training job, deployment, test\n",
    "        run_local_orchestration()\n",
    "    else:\n",
    "        # Filter out Jupyter's '-f /path/to/kernel.json' or other unknown args\n",
    "        filtered_args = [\n",
    "            arg for arg in sys.argv[1:] \n",
    "            if arg.startswith(\"--\") or arg in (\"-h\", \"--help\")\n",
    "        ]\n",
    "        new_sys_argv = [sys.argv[0]] + filtered_args\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\n",
    "            \"--train\",\n",
    "            type=str,\n",
    "            default=os.environ.get(\"SM_CHANNEL_TRAIN\", os.path.abspath(\"project_data\")),\n",
    "            help=\"Path to training directory containing train.csv\"\n",
    "        )\n",
    "        parser.add_argument(\n",
    "            \"--model-dir\",\n",
    "            type=str,\n",
    "            default=os.environ.get(\"SM_MODEL_DIR\", os.path.abspath(\"model_output\")),\n",
    "            help=\"Where to save the trained model artifacts\"\n",
    "        )\n",
    "\n",
    "        parsed_args, _ = parser.parse_known_args(new_sys_argv[1:])\n",
    "        train_dir = parsed_args.train\n",
    "        model_dir = parsed_args.model_dir\n",
    "\n",
    "        run_training(train_dir, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299ef51-7377-498c-b938-01abeb22127e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17121ca-f243-46b3-851c-d42a256253a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee19e0-c321-4f4b-8330-7f0e0dde1a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c006dd2-d2cb-4857-b421-2932d81c8a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b2fcf-6a27-4ad1-b095-839a9fa9e65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c6864-b81a-481f-8312-a0d6932a1288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
